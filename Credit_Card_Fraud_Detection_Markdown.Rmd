---
title: "Credit Card Fraud Detection"
editor_options: null
output:
  pdf_document: default
  html_document:
    df_print: paged
chunk_output_type: inline
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = TRUE)
```

## Introduction
The subject of the project is fraud detection in transactions with credit cards. Detecting fraud can save lots of money and prevent loses. To do that two different methods are utilized. The first one is Recursive Partitioning and the second approach is Random Forest.

creditcardfraud dataset is used in this project which is a public dataset and can be downloaded by the following link:

https://www.kaggle.com/mlg-ulb/creditcardfraud

Following libraries are used in this project:
```{r}
set.seed(1, sample.kind="Rounding")
if(!require(tidyverse))  install.packages("tidyverse")
if(!require(randomForest))  install.packages("randomForest")
if(!require(imbalance))  install.packages("imbalance")
if(!require(caret))  install.packages("caret")
if(!require(e1071))  install.packages("e1071")
if(!require(Metrics))  install.packages("Metrics")


library(tidyverse)
library(randomForest)
library(imbalance)
library(caret)
library(e1071)
library(Metrics)

```


#### Preparing the data
From the given link the dataset in form of csv file is downloaded (*creditcard.csv*) and saved in the same folder as the script file and .rmd file.
Now we can use the following piece of code to have a look at the dataset.

```{r}
gc()
credit_card_data <- read.table(file = "creditcard.csv", sep = ",", header=TRUE)
glimpse(credit_card_data)
```

As we can see there are in total 31 columns in the dataset. The time is not considered to be relevant to our analysis. *Class* shows whether the transaction is a fraud (Class = 1) or a non-fraud (Class = 0). We might guess that the number of observations which belong to Class 0 is by far more than those which belong to Class 1. We can verify this by the following code.

```{r}
n_fraud_not_fraud <- credit_card_data %>% count(Class) 
print(n_fraud_not_fraud)
```

Since time column is not relevant to our model, we remove it from the dataset.
Now we have 29 features(*V1-V28* and *Amount*) and the goal is to predict the *Class* of the transaction. 

As we see, fraud transactions are only a tiny fraction (0.17%) of all observations. This means, if we predict all transaction are non-fraud, we still have a accuracy of 99.8% which obviously is not correct.

To solve this issue we need to *balance* the dataset. To do that there are two techniques. The first one is to undersample the dominant class (Class 0) and the second one is to oversample the class which has less members (Class 1). Here, we use *pdfos* function from *imbalance* library to do oversampling. 
```{r}
credit_card_data_noTime <- subset (credit_card_data, select = -Time)
new_fraud_data <- pdfos(credit_card_data_noTime, numInstances = 
                          n_fraud_not_fraud$n[1] - n_fraud_not_fraud$n[2])
new_credit_card_data <- rbind(credit_card_data_noTime, new_fraud_data)
new_n_fraud_not_fraud <- new_credit_card_data %>% count(Class) 
rm(credit_card_data, credit_card_data_noTime, new_fraud_data)
glimpse(new_credit_card_data)
```
As we see, the number of rows in each class is the same in this new dataset. We also need to convert *Class* column to factor type.
```{r}
new_credit_card_data$Class <- factor(new_credit_card_data$Class)

```

Now we have a dataset which we can use for training and testing our machine learning models.
Training and testing datasets are created by following lines of codes.

```{r}
test_index <- createDataPartition(y = new_credit_card_data$Class, 
                                  times = 1, p = 0.1, list = FALSE)
training_data <- new_credit_card_data[-test_index,]
test_data <- new_credit_card_data[test_index,]
rm(new_credit_card_data)
```

## Methods

Two different models are used in this project. The first one uses *Recursive Partitioning* and the second approach uses Random Forest. 

#### Recursive Partitioning
In this approach we use *rpart* library. 
```{r}
if(!require(rpart))  install.packages("rpart")
library(rpart)
```
We want to predict *Class* by using the given 29 features. 

```{r}
fit <- rpart(Class~., data = training_data, method = 'class')
```

We can visualize our model by *fancyRpartPlot* function as shown in the following code.

```{r}
if(!require(rattle))  install.packages("rattle")
if(!require(rpart.plot))  install.packages("rpart.plot")
if(!require(RColorBrewer))  install.packages("RColorBrewer")

library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(fit, caption = NULL)
```

To see how our model perform, we do prediction on the test data as follows. The *Confusion Matrix* is used to evaluate the predicted results.

```{r}
pred_DT <- predict(object= fit, newdata = test_data, type = 'class')
conf_DT <- confusionMatrix(pred_DT,test_data[['Class']])
overall_accuracy <- conf_DT$overall[['Accuracy']]
sensitivity <- conf_DT$byClass[['Sensitivity']]
specificity <- conf_DT$byClass[['Specificity']]

print(conf_DT)
print(paste('Overall accuracy: ',overall_accuracy))
print(paste('Sensitivity: ',sensitivity))
print(paste('Specificity: ',specificity))
```

As we can see the overall accuracy, sensitivity and specificity are 96.61%, 0.9603 and 0.9719 respectively.

#### Random Forest

Another approach for this classification problem is the random forest. This method is an ensemble learning method. In this approach, several decision trees are created. These trees are used to build up the forest. It can achieve higher accuracy than a single decision tree. To do that, it uses feature randomness and bootstrap aggregating (also know as bagging). Here, *randomForest* function from *randomForest* library is used to create a random forest. We can set the number of randomly sampled variables by *mtry* and the number of trees by *ntree*. First we run the code for 6 different *mtry*.

```{r}
mtry_i <- c(1:6,rep(3,4))
ntree_i <- c(rep(50,6),seq(10,70,by = 20))
sensitivity_i <- numeric(10)
specificity_i <- numeric(10)
overall_accuracy <- numeric(10)
for (i in 1:6){
gc()
rf_classifier <- randomForest(formula = Class ~ ., data = 
                                training_data,ntree=ntree_i[i],
                              mtry= mtry_i[i], importance = TRUE)
pred <- predict(rf_classifier, test_data)
conf <- confusionMatrix(pred,test_data[['Class']])
overall_accuracy[i] <- conf$overall[['Accuracy']]
sensitivity_i[i] <- conf$byClass[['Sensitivity']]
specificity_i[i] <- conf$byClass[['Specificity']]
number_of_trees <- 1:ntree_i[i]
}

tab_1 <- data.frame(mtry = mtry_i[1:6],ntree= rep(50,6),
                    overall_accuracy = overall_accuracy[1:6],
                    Sensitivity = sensitivity_i[1:6]
                    , Specificity = specificity_i[1:6])
print(tab_1)

```

From the above table, we can see the best result is obtained when *mtry* is equal to 3. Now we set *mtry* to 3 and change the number of trees (*ntree*). We choose *ntree* to be 10,30,50 and 70.  

```{r}
gc()
for (i in 7:10){
gc()
rf_classifier <- randomForest(formula = Class ~ ., data =
                                  training_data,ntree=ntree_i[i],
                              mtry= mtry_i[i], importance = TRUE)
pred <- predict(rf_classifier, test_data)
conf <- confusionMatrix(pred,test_data[['Class']])
overall_accuracy[i] <- conf$overall[['Accuracy']]
sensitivity_i[i] <- conf$byClass[['Sensitivity']]
specificity_i[i] <- conf$byClass[['Specificity']]
number_of_trees <- 1:ntree_i[i]
}
```


```{r}
tab_2 <- data.frame(mtry = mtry_i,ntree= ntree_i,
                    overall_accuracy = overall_accuracy,
                    Sensitivity = sensitivity_i, Specificity = specificity_i)

print(tab_2)
gc()
```

All the results are presented in the above table. The row number 9 gives the best results. In this row we have 50 *trees* in the forest and *mtry* is 3.

## Conclusion

Recursive partitioning and random forest models are used in this project to detect frauds in the credit cards transactions. Overall accuracy, sensitivity and specificity are chosen to assess the performance of the models.

Although both models give high accuracy results, the random forest is a better alternative when the parameters are set appropriately. The best model is a random forest with 50 trees and *mtry* equal tree. In this case, overall accuracy, sensitivity and specificity are 99.88%, 0.9989 and 0.9987 respectively.